{"cells":[{"metadata":{},"cell_type":"markdown","source":"# DSL Project - BatchBoost\n# Piyush Raj Gupta, Gaurav, Bhushan Chaudhari\n# Mentor - Sujoy Bhattacharya"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/batchboost.py\n/kaggle/input/.gitignore\n/kaggle/input/plot.py\n/kaggle/input/LICENSE\n/kaggle/input/LICENSE-pytorch-cifar\n/kaggle/input/debug.py\n/kaggle/input/utils.py\n/kaggle/input/train.py\n/kaggle/input/README.md\n/kaggle/input/results/decay=1e-5/loss-test-without-augment-.pdf\n/kaggle/input/results/decay=1e-5/log_EfficientNet_batchboost_2.csv\n/kaggle/input/results/decay=1e-5/log_EfficientNet_baseline_13.csv\n/kaggle/input/results/decay=1e-5/test-accuracy-without-augment-.pdf\n/kaggle/input/results/decay=1e-5/train-accuracy-without-augment-.pdf\n/kaggle/input/results/decay=1e-5/log_EfficientNet_baseline_24.csv\n/kaggle/input/results/decay=1e-5/loss-test-with-augment-.pdf\n/kaggle/input/results/decay=1e-5/log_EfficientNet_mixup_3.csv\n/kaggle/input/results/decay=1e-5/log_EfficientNet_batchboost_3.csv\n/kaggle/input/results/decay=1e-5/log_EfficientNet_mixup_2.csv\n/kaggle/input/results/decay=1e-5/log_EfficientNet_batchboost_4.csv\n/kaggle/input/results/decay=1e-5/log_EfficientNet_mixup_1.csv\n/kaggle/input/results/decay=1e-5/log_EfficientNet_batchboost_1.csv\n/kaggle/input/results/decay=1e-5/test-accuracy-with-augment-.pdf\n/kaggle/input/results/decay=1e-5/log_EfficientNet_mixup_4.csv\n/kaggle/input/results/decay=1e-5/train-accuracy-with-augment-.pdf\n/kaggle/input/results/decay=1e-4/loss-test-without-augment-.pdf\n/kaggle/input/results/decay=1e-4/log_EfficientNet_batchboost_2.csv\n/kaggle/input/results/decay=1e-4/log_EfficientNet_baseline_13.csv\n/kaggle/input/results/decay=1e-4/test-accuracy-without-augment-.pdf\n/kaggle/input/results/decay=1e-4/train-accuracy-without-augment-.pdf\n/kaggle/input/results/decay=1e-4/log_EfficientNet_baseline_24.csv\n/kaggle/input/results/decay=1e-4/loss-test-with-augment-.pdf\n/kaggle/input/results/decay=1e-4/log_EfficientNet_mixup_3.csv\n/kaggle/input/results/decay=1e-4/log_EfficientNet_batchboost_3.csv\n/kaggle/input/results/decay=1e-4/log_EfficientNet_mixup_2.csv\n/kaggle/input/results/decay=1e-4/log_EfficientNet_batchboost_4.csv\n/kaggle/input/results/decay=1e-4/log_EfficientNet_mixup_1.csv\n/kaggle/input/results/decay=1e-4/log_EfficientNet_batchboost_1.csv\n/kaggle/input/results/decay=1e-4/test-accuracy-with-augment-.pdf\n/kaggle/input/results/decay=1e-4/log_EfficientNet_mixup_4.csv\n/kaggle/input/results/decay=1e-4/train-accuracy-with-augment-.pdf\n/kaggle/input/figures/figure-multipass.png\n/kaggle/input/figures/data_6.png\n/kaggle/input/figures/for-repository-1.png\n/kaggle/input/figures/figure-2-test-accuracy-with-augment.pdf\n/kaggle/input/figures/data_4.png\n/kaggle/input/figures/data_2.png\n/kaggle/input/figures/figure-abstract.pdf\n/kaggle/input/figures/figure-abstract.svg\n/kaggle/input/figures/figure-1-loss-train-without-augment.pdf\n/kaggle/input/figures/data_5.png\n/kaggle/input/figures/figure-feeding.pdf\n/kaggle/input/figures/data_7.png\n/kaggle/input/figures/figure-1-test-accuracy-without-augment.pdf\n/kaggle/input/figures/for-repository-2.png\n/kaggle/input/figures/figure-abstract.png\n/kaggle/input/figures/pp_logo.jpg\n/kaggle/input/figures/figure-2-train-accuracy-with-augment.pdf\n/kaggle/input/figures/figure-feeding.png\n/kaggle/input/figures/figure-feeding.svg\n/kaggle/input/figures/data_1.png\n/kaggle/input/figures/data_3.png\n/kaggle/input/figures/batches/img_4_new_11.png\n/kaggle/input/figures/batches/img_3_new_8.png\n/kaggle/input/figures/batches/img_4_new_7.png\n/kaggle/input/figures/batches/img_1_old_1.png\n/kaggle/input/figures/batches/img_1_new_10.png\n/kaggle/input/figures/batches/img_2_new_10.png\n/kaggle/input/figures/batches/img_1_new_6.png\n/kaggle/input/figures/batches/img_3_new_10.png\n/kaggle/input/figures/batches/img_2_old_2.png\n/kaggle/input/figures/batches/img_3_old_1.png\n/kaggle/input/figures/batches/img_1_old_0.png\n/kaggle/input/figures/batches/img_1_old_4.png\n/kaggle/input/figures/batches/img_4_old_5.png\n/kaggle/input/figures/batches/img_2_old_4.png\n/kaggle/input/figures/batches/img_3_new_11.png\n/kaggle/input/figures/batches/img_1_new_11.png\n/kaggle/input/figures/batches/img_1_old_3.png\n/kaggle/input/figures/batches/img_4_old_0.png\n/kaggle/input/figures/batches/img_3_old_3.png\n/kaggle/input/figures/batches/img_4_old_4.png\n/kaggle/input/figures/batches/img_2_new_8.png\n/kaggle/input/figures/batches/img_4_old_1.png\n/kaggle/input/figures/batches/img_3_old_2.png\n/kaggle/input/figures/batches/img_2_old_3.png\n/kaggle/input/figures/batches/img_2_new_9.png\n/kaggle/input/figures/batches/img_2_old_1.png\n/kaggle/input/figures/batches/img_2_new_6.png\n/kaggle/input/figures/batches/img_3_new_9.png\n/kaggle/input/figures/batches/img_4_new_9.png\n/kaggle/input/figures/batches/img_1_new_7.png\n/kaggle/input/figures/batches/img_4_old_2.png\n/kaggle/input/figures/batches/img_4_new_6.png\n/kaggle/input/figures/batches/img_1_old_2.png\n/kaggle/input/figures/batches/img_3_old_5.png\n/kaggle/input/figures/batches/img_3_new_6.png\n/kaggle/input/figures/batches/img_3_new_7.png\n/kaggle/input/figures/batches/img_1_old_5.png\n/kaggle/input/figures/batches/img_4_new_8.png\n/kaggle/input/figures/batches/img_3_old_0.png\n/kaggle/input/figures/batches/img_2_old_5.png\n/kaggle/input/figures/batches/img_3_old_4.png\n/kaggle/input/figures/batches/img_4_new_10.png\n/kaggle/input/figures/batches/img_2_new_11.png\n/kaggle/input/figures/batches/img_1_new_9.png\n/kaggle/input/figures/batches/img_2_old_0.png\n/kaggle/input/figures/batches/img_2_new_7.png\n/kaggle/input/figures/batches/img_1_new_8.png\n/kaggle/input/figures/batches/img_4_old_3.png\n/kaggle/input/models/alldnet.py\n/kaggle/input/models/resnext.py\n/kaggle/input/models/__init__.py\n/kaggle/input/models/densenet.py\n/kaggle/input/models/densenet3.py\n/kaggle/input/models/resnet.py\n/kaggle/input/models/vgg.py\n/kaggle/input/models/densenet_efficient_multi_gpu.py\n/kaggle/input/models/mobilenet.py\n/kaggle/input/models/googlenet.py\n/kaggle/input/models/lenet.py\n/kaggle/input/paper/figure-multipass.png\n/kaggle/input/paper/build.py\n/kaggle/input/paper/arxiv-abstract.png\n/kaggle/input/paper/notes_v2.md\n/kaggle/input/paper/references.bib\n/kaggle/input/paper/arxiv-abstract-shadow.png\n/kaggle/input/paper/figure-2-test-accuracy-with-augment.pdf\n/kaggle/input/paper/figure-abstract.pdf\n/kaggle/input/paper/figure-1-loss-train-without-augment.pdf\n/kaggle/input/paper/abstract.txt\n/kaggle/input/paper/figure-feeding.pdf\n/kaggle/input/paper/texput.log\n/kaggle/input/paper/figure-1-test-accuracy-without-augment.pdf\n/kaggle/input/paper/arxiv.sty\n/kaggle/input/paper/batchboost.pdf\n/kaggle/input/paper/batchboost.tex\n/kaggle/input/paper/figure-2-train-accuracy-with-augment.pdf\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"In this research, we state the hypothesis that mixing many images together can be more effective than just two. To make it efficient, we propose a new method of creating mini-batches, where each sample from dataset is propagated with subsequent iterations with less and less importance until the end of learning process.\n\nBatchboost pipeline has three stages: \n(a) pairing: method of selecting two samples from previous step. \n\n(b) mixing: method of creating a new artificial example from two selected samples. \n\n(c) feeding: constructing training mini-batch with created examples and new samples from dataset (concat with ratio Î³). Note that sample from dataset propagates with subsequent iterations with less and less importance until the end of training."},{"metadata":{},"cell_type":"markdown","source":"File batchboost.py is portable, just copy into your path and it will act as library so that you can just import this file and accesss the functionality just calling the functions."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from shutil import copyfile\ncopyfile(src = \"../input/batchboost.py\", dst = \"../working/batchboost.py\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing BatchBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from batchboost import BatchBoost","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can apply batchboost technique on any deep learning model which is performing image claasification task. Here we are applying batchboost for classification of CIFAR10 dataset to a transfer learning model."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install efficientnet-pytorch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use python train.py to train a new model. Here is an example setting. \n\nYou can use different parameters for model which can be passed from command line as shown in figure below.\n\nArguments-\n1)CUDA availability\n\n2)Learning Rate\n\n3)Seeding Factor\n\n4)Sample Pairing technique(Mixup/BatchBoost)\n\n5)Model used in transfer Learning(Resnet,Efficient Net etc)\n\n6)Number of epochs"},{"metadata":{"trusted":true},"cell_type":"code","source":"!CUDA_VISIBLE_DEVICES=0 python3 /kaggle/input/train.py --decay=1e-4 --no-augment --seed=1 \\\n\t--name=batchboost --model=efficientnet-b0 --epoch=30","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}