{"cells":[{"metadata":{},"cell_type":"markdown","source":"# DSL Lab project (Transfer Learnign -ResNet, EfficientNet)\n# Piyush Raj Gupta, Gaurav, Bhushan Chaudhari\n# Mentor - Sujoy Bhattacharya"},{"metadata":{},"cell_type":"markdown","source":"A teacher has years of experience in the particular topic he/she teaches. With all this accumulated information, the lectures that students get is a concise and brief overview of the topic. So it can be seen as a “transfer” of information from the learned to a novice.\n\nKeeping in mind this analogy, we compare this to neural network. A neural network is trained on a data. This network gains knowledge from this data, which is compiled as “weights” of the network. These weights can be extracted and then transferred to any other neural network. Instead of training the other neural network from scratch, we “transfer” the learned features.\n\nLet’s look at the steps we will be following to train the model using transfer learning:\n\n1)First, we will load the weights of the pre-trained model – ResNet/EfficientNet in our case\n\n2)Then we will fine tune the model as per the problem at hand\n\n3)Next, we will use these pre-trained weights and extract features for our images\n\n4)Finally, we will train the fine tuned model using the extracted features"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading Important Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nimport tensorflow.keras as keras\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nimport tensorflow as tf\nfrom keras.utils import np_utils\nfrom keras.models import load_model\nfrom keras.datasets import cifar10\nfrom keras.preprocessing import image\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ResNet, short for Residual Networks is a classic neural network used as a backbone for many computer vision tasks. This model was the winner of ImageNet challenge in 2015. The fundamental breakthrough with ResNet was it allowed us to train extremely deep neural networks with 150+layers successfully.\n\nDownloading Pretrained resnet model in following step."},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base = ResNet50(weights='imagenet', include_top=False, input_shape=(200, 200, 3))","execution_count":3,"outputs":[{"output_type":"stream","text":"Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94773248/94765736 [==============================] - 7s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We know that the pixel values for each image in the dataset are unsigned integers in the range between no color and full color, or 0 and 255.\n\nWe do not know the best way to scale the pixel values for modeling, but we know that some scaling will be required.\n\nA good starting point is to normalize the pixel values, e.g. rescale them to the range [0,1]. This involves first converting the data type from unsigned integers to floats, then dividing the pixel values by the maximum value."},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\nx_train = x_train / 255.0\nx_test = x_test / 255.0\n\ny_train = np_utils.to_categorical(y_train, 10)\ny_test = np_utils.to_categorical(y_test, 10)\n\nprint(x_train.shape)\nprint(x_test.shape)","execution_count":4,"outputs":[{"output_type":"stream","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170500096/170498071 [==============================] - 11s 0us/step\n(50000, 32, 32, 3)\n(10000, 32, 32, 3)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Define a model. We will  freeze all layers and will tune top 2 fully connected layers according to our problem statement."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.UpSampling2D((2,2)))\nmodel.add(layers.UpSampling2D((2,2)))\nmodel.add(layers.UpSampling2D((2,2)))\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dense(10, activation='softmax'))\n\nmodel.compile(optimizer=optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['acc'])\n\nhistory = model.fit(x_train, y_train, epochs=3, batch_size=32, validation_data=(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Saving Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('my_model.h5') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Graphs for visualising underfitting and overfitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_train = history.history['acc']\nloss_val = history.history['val_acc']\nepochs = range(1,11)\nplt.plot(epochs, loss_train, 'g', label='Training accuracy')\nplt.plot(epochs, loss_val, 'b', label='validation accuracy')\nplt.title('Training and Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_train = history.history['train_loss']\nloss_val = history.history['val_loss']\nepochs = range(1,4)\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculating accuracy on validation dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Efficient Net"},{"metadata":{},"cell_type":"markdown","source":"Same procedure has been repeated just in this case we had used efficient net as pretrained model on the place of resnet"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.datasets import cifar10\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Activation, BatchNormalization, Flatten\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import Adam\nimport efficientnet.keras as enet\nfrom efficientnet_pytorch import EfficientNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install efficientnet_pytorch\nconv_base = model = EfficientNet.from_pretrained('efficientnet-b0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\nx_train = x_train / 255.0\nx_test = x_test / 255.0\n\ny_train = np_utils.to_categorical(y_train, 10)\ny_test = np_utils.to_categorical(y_test, 10)\n\nprint(x_train.shape)\nprint(x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dense(10, activation='softmax'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel.compile(optimizer=optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['acc'])\n\nhistory = model.fit(x_train, y_train, epochs=3, batch_size=32, validation_data=(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_train = history.history['train_loss']\nloss_val = history.history['val_loss']\nepochs = range(1,4)\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_train = history.history['acc']\nloss_val = history.history['val_acc']\nepochs = range(1,11)\nplt.plot(epochs, loss_train, 'g', label='Training accuracy')\nplt.plot(epochs, loss_val, 'b', label='validation accuracy')\nplt.title('Training and Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(x_test, y_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}